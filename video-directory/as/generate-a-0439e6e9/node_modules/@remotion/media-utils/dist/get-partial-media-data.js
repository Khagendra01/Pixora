"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.getPartialMediaData = void 0;
const media_parser_1 = require("@remotion/media-parser");
const worker_1 = require("@remotion/media-parser/worker");
const webcodecs_1 = require("@remotion/webcodecs");
const getPartialMediaData = async ({ src, fromSeconds, toSeconds, channelIndex, signal, }) => {
    const controller = (0, media_parser_1.mediaParserController)();
    // Collect audio samples
    const audioSamples = [];
    // Abort if the signal is already aborted
    if (signal.aborted) {
        throw new Error('Operation was aborted');
    }
    try {
        if (fromSeconds > 0) {
            controller.seek(fromSeconds);
        }
        await (0, worker_1.parseMediaOnWebWorker)({
            src,
            controller,
            onAudioTrack: ({ track }) => {
                if (!track) {
                    throw new Error('No audio track found');
                }
                const audioDecoder = (0, webcodecs_1.createAudioDecoder)({
                    track,
                    onFrame: (sample) => {
                        if (signal.aborted) {
                            sample.close();
                            return;
                        }
                        // For multi-channel audio, we need to handle channels properly
                        const { numberOfChannels } = sample;
                        const samplesPerChannel = sample.numberOfFrames;
                        let data;
                        if (numberOfChannels === 1) {
                            // Mono audio
                            data = new Float32Array(sample.allocationSize({ format: 'f32', planeIndex: 0 }));
                            sample.copyTo(data, { format: 'f32', planeIndex: 0 });
                        }
                        else {
                            // Multi-channel audio: extract specific channel
                            const allChannelsData = new Float32Array(sample.allocationSize({ format: 'f32', planeIndex: 0 }));
                            sample.copyTo(allChannelsData, { format: 'f32', planeIndex: 0 });
                            // Extract the specific channel (interleaved audio)
                            data = new Float32Array(samplesPerChannel);
                            for (let i = 0; i < samplesPerChannel; i++) {
                                data[i] = allChannelsData[i * numberOfChannels + channelIndex];
                            }
                        }
                        audioSamples.push(data);
                        sample.close();
                    },
                    onError(error) {
                        throw error;
                    },
                });
                // Listen for abort signal
                const onAbort = () => {
                    controller.abort();
                    if (audioDecoder) {
                        audioDecoder.close();
                    }
                };
                signal.addEventListener('abort', onAbort, { once: true });
                return async (sample) => {
                    if (signal.aborted) {
                        return;
                    }
                    // Convert timestamp using the track's timescale
                    const time = sample.timestamp / track.timescale;
                    // Stop immediately when we reach our target time
                    if (time >= toSeconds) {
                        // abort media parsing, we reached the point where we want to stop
                        controller.abort();
                        await audioDecoder.flush();
                        return;
                    }
                    // Decode the sample using the sample directly
                    await audioDecoder.waitForQueueToBeLessThan(10);
                    // we're waiting for the queue above anyway, enqueue in sync mode
                    audioDecoder.decode(sample);
                };
            },
        });
    }
    catch (err) {
        const isAbortedByTimeCutoff = (0, media_parser_1.hasBeenAborted)(err);
        // Don't throw if we stopped the parsing ourselves
        if (!isAbortedByTimeCutoff && !signal.aborted) {
            throw err;
        }
    }
    // Simply concatenate all audio data since windowing handles the time ranges
    const totalSamples = audioSamples.reduce((sum, sample) => sum + sample.length, 0);
    const result = new Float32Array(totalSamples);
    let offset = 0;
    for (const audioSample of audioSamples) {
        result.set(audioSample, offset);
        offset += audioSample.length;
    }
    return result;
};
exports.getPartialMediaData = getPartialMediaData;
